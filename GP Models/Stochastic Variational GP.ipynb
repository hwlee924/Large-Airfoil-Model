{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d67a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Multitask model\n",
    "\n",
    "\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from gpytorch.constraints import Positive\n",
    "from scipy.ndimage import generic_filter\n",
    "from gpytorch.constraints import GreaterThan\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "#Load in data\n",
    "\n",
    "df = pd.read_csv('C:/Users/Tom/OneDrive - Georgia Institute of Technology/Desktop/CEREAL Repo/demo_outboard_CEREAL_edited.csv') \n",
    "x = torch.tensor(df[['r','z','azim']].values, dtype=torch.float32)\n",
    "y = torch.tensor(df[['Vmag']].values, dtype=torch.float32).flatten()\n",
    "Vr = torch.tensor(df[['Vr']].values, dtype=torch.float32).flatten()\n",
    "Vz = torch.tensor(df[['Vz']].values, dtype=torch.float32).flatten()\n",
    "y_stand = (y - y.mean())/y.std()  #Standardize output\n",
    "mask = ~torch.isnan(y)\n",
    "x = x[mask]\n",
    "y = y[mask]\n",
    "Vr = Vr[mask]\n",
    "Vz = Vz[mask]\n",
    "#y_stand = y_stand[mask]\n",
    "print(y)\n",
    "#Define x and y coordinates, should y being velo magnitude?\n",
    "\n",
    "#Define fourier kernel\n",
    "train_x = torch.tensor(x)\n",
    "train_y = torch.stack([Vr,Vz],dim=-1)\n",
    "class FourierKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True # Required for kronecker\n",
    "    def __init__(self, harmonics, active_dims = None):\n",
    "        # initialize kernel \n",
    "        super().__init__(has_lengthscale=True, active_dims = active_dims)\n",
    "        n_lambdas = 2*len(harmonics)+1\n",
    "\n",
    "        # Define hyperparameter, lambda \n",
    "            ###Change 1- Initialize lambda at 0.5, rather than 0\n",
    "        self.register_parameter(name=\"raw_lambdas\", parameter=torch.nn.Parameter(torch.ones(n_lambdas)*0.5)) #Initialize to 0.5 \n",
    "        #self.register_constraint(\"raw_lambdas\", Positive()) \n",
    "        self.register_constraint(\"raw_lambdas\", GreaterThan(1e-6))\n",
    "        \n",
    "        self.HARMONICS = harmonics\n",
    "        \n",
    "        # Define prior\n",
    "            ##Change 2- Set prior to multivariate normal prior centered at 0.5 with small variance\n",
    "        self.register_prior(\n",
    "                \"lambdas_prior\",\n",
    "                gpytorch.priors.MultivariateNormalPrior(torch.ones(n_lambdas)*0.5, torch.eye(n_lambdas)*0.1), # gpytorch.priors.NormalPrior(1.5, 0.5)\n",
    "                lambda m: m.lambdas,\n",
    "                lambda m, v : m._set_lambdas(v),)\n",
    "    \n",
    "    # Set fx related to hyperparams\n",
    "    @property\n",
    "    def lambdas(self):\n",
    "        # when accessing the parameter, apply the constraint transform\n",
    "        return self.raw_lambdas_constraint.transform(self.raw_lambdas)\n",
    "    @lambdas.setter\n",
    "    def lambdas(self, values):\n",
    "        return self._set_lambdas(values)\n",
    "    def _set_lambdas(self, values):\n",
    "        if not torch.is_tensor(values):\n",
    "            values = torch.as_tensor(values).to(self.lambdas)\n",
    "        # when setting the paramater, transform the actual value to a raw one by applying the inverse transform\n",
    "        self.initialize(raw_lambdas=self.lambdas_constraint.inverse_transform(values))\n",
    "\n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "        Fa = self.fourier_matrix_fast(x1[:,0], self.HARMONICS) # in Hz\n",
    "        Fb = self.fourier_matrix_fast(x2[:,0], self.HARMONICS) # in Hz\n",
    "        if use_gpu:\n",
    "            k = Fa @ torch.diag(self.lambdas) @ Fb.T \n",
    "        else: \n",
    "            k = Fa @ torch.diag(self.lambdas) @ Fb.T \n",
    "        if diag==False:\n",
    "            return k\n",
    "        else: \n",
    "            return torch.diag(k)\n",
    "\n",
    "    def fourier_matrix_fast(self, circumferential_locations, harmonics):\n",
    "        num_harmonics = len(harmonics)\n",
    "        interweaved_idx = torch.tensor(list(zip(range(num_harmonics), range(num_harmonics, 2*num_harmonics)))) \n",
    "        \n",
    "        harmonics = torch.tensor(harmonics, dtype=torch.float32\n",
    "                                 )\n",
    "        X1 = torch.sin(torch.outer(harmonics, circumferential_locations))\n",
    "        X2 = torch.cos(torch.outer(harmonics, circumferential_locations))\n",
    "        XX = torch.cat((X1.T, X2.T), dim=1)\n",
    " \n",
    "        XX = XX[:, interweaved_idx.flatten()]\n",
    "        # print('6')\n",
    "        ones_column = torch.ones((circumferential_locations.shape[0], 1), )##device=circumferential_locations.device\n",
    "        # print('7')\n",
    "        if use_gpu:\n",
    "            XX = torch.cat((ones_column.cuda(), XX), dim=1)\n",
    "            \n",
    "        else: \n",
    "            XX = torch.cat((ones_column, XX), dim=1)\n",
    "        return XX\n",
    "    \n",
    "\n",
    "# THIS IS PSEUDO CODE\n",
    "# this assumes training data will be N x 3 (r, z, psi)\n",
    "\n",
    "class MultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self,train_x,train_y,likelihood):\n",
    "        super(MultitaskGPModel,self).__init__(train_x,train_y,likelihood)\n",
    "        self.mean_module = gpytorch.means.MultitaskMean(\n",
    "            gpytorch.means.ConstantMean(),num_tasks=2\n",
    "        )\n",
    "        self.covar_module = gpytorch.kernels.MultitaskKernel(gpytorch.kernels.MaternKernel(active_dims=[0,1],\n",
    "                                                                                          ard_num_dims=2,\n",
    "                                                                                          nu=5/2,\n",
    "                                                                                          lengthscale_prior=gpytorch.priors.HalfNormalPrior(0.5))*FourierKernel(harmonics=[1,2,3,4,5,6,7,8,9,10],active_dims=[2]),\n",
    "                                                                                          num_tasks=2,rank=1\n",
    "                                                            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultitaskMultivariateNormal(mean_x,covar_x)\n",
    "\n",
    "\n",
    "\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=2)\n",
    "likelihood.noise = 0.001\n",
    "likelihood.register_prior(\"noise_prior\",gpytorch.priors.GammaPrior(1.5,10),\"noise\")\n",
    "model = MultitaskGPModel(train_x, train_y, likelihood) #Call on GP model\n",
    "model.train()\n",
    "likelihood.train() # For optimizer setup \n",
    "use_gpu=False\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Includes GaussianLikelihood parameters\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model) #Loss function\n",
    "\n",
    "training_iter = 250\n",
    "for i in range(training_iter):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x) \n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Iter {i+1}/{training_iter} - Loss: {loss.item():.3f}\")\n",
    "\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "\n",
    "r_grid = np.linspace(df['r'].min(), df['r'].max(), 50)\n",
    "z_grid = np.linspace(df['z'].min(), df['z'].max(), 50)\n",
    "R, Z = np.meshgrid(r_grid, z_grid)\n",
    "#Az = np.zeros_like(R)  # Fix azimuthal angle at 0 for 2D slice\n",
    "Az = np.zeros_like(R)  # Fix azimuthal angle at 0 for 2D slice\n",
    "print(Az)\n",
    "x_test = torch.tensor(np.vstack([R.ravel(), Z.ravel(), Az.ravel()]), dtype=torch.float32).T\n",
    "print(np.shape(x_test))\n",
    "#with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#    pred = likelihood(model(x_test))\n",
    "#    Vr_pred = pred.mean[:,0].numpy().reshape(R.shape)\n",
    "#    Vz_pred = pred.mean[:,1].numpy().reshape(R.shape)\n",
    "#    Vr_var = pred.variance[:,0].numpy().reshape(R.shape)\n",
    "#    Vz_var = pred.variance[:,1].numpy().reshape(R.shape)\n",
    "\n",
    "#Azimuth sweep to plot predictions\n",
    "#azim_vec = np.linspace(df['azim'].min(), df['azim'].max(), 20)\n",
    "#fig,axes = plt.subplots(2,4,figsize=(15,13),constrained_layout = True)\n",
    "#for ax, az in zip(axes.ravel(), azim_vec):\n",
    "#    Az = np.full_like(R, az)\n",
    "#    x_test = torch.tensor(np.vstack([R.ravel(), Z.ravel(), Az.ravel()]), dtype=torch.float32).T\n",
    "#    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "#        pred = likelihood(model(x_test))\n",
    "#        Vr_pred = pred.mean[:,0].numpy().reshape(R.shape)\n",
    "#        Vz_pred = pred.mean[:,1].numpy().reshape(R.shape)\n",
    "#        Vr_var = pred.variance[:,0].numpy().reshape(R.shape)\n",
    "#        Vz_var = pred.variance[:,1].numpy().reshape(R.shape)\n",
    "#    q = ax.quiver(R, Z, Vr_pred, Vz_pred,cmap='viridis')\n",
    "#    ax.set_title(f\"azim = {az:.2f} rad\")\n",
    "#    ax.set_xlabel('R')\n",
    "#    ax.set_ylabel('Z')\n",
    "#fig.colorbar(cp, ax=axes.ravel().tolist(), label='Predicted vmag (normalized mean)')\n",
    "#plt.suptitle('GP Predictions of Vr,Vz at Various Azimuthal Angles')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
